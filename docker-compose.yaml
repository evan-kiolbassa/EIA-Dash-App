version: "3.9"

services:
  cassandra:
    build: ./docker/cassandra
    image: cassandra:latest
    container_name: cassandra
    ports:
      - "9042:9042"
    restart: always
    environment:
      - CASSANDRA_START_RPC=true

  spark:
    build: ./docker/spark
    image: my-spark:latest
    container_name: spark
    depends_on:
      - cassandra
    environment:
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_APPLICATION_PYTHON_LOCATION=/app/my_spark_app.py
      - SPARK_APPLICATION_ARGS="arg1 arg2"
    volumes:
      - ./app:/app
    restart: always

  airflow:
    build: ./docker/airflow
    image: apache/airflow:latest
    container_name: airflow
    depends_on:
      - spark
      - cassandra
    ports:
      - "8080:8080"
    restart: always
    environment:
      - EXECUTOR=Local
      - LOAD_EXAMPLES=yes
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    command: >
      bash -c "airflow db init &&
               airflow users create --username admin --password admin --firstname Admin --lastname Admin --role Admin --email admin@example.com &&
               airflow webserver"
  web:
    build: ./docker/web
    container_name: web
    command: gunicorn app:server -b 0.0.0.0:8050
    ports:
      - "8050:8050"
    environment:
      - FLASK_APP=app.py
      - FLASK_ENV=development
    volumes:
      - ./app:/app
    restart: always